# Main entrypoint of the workflow. 
# Please follow the best practices: 
# https://snakemake.readthedocs.io/en/stable/snakefiles/best_practices.html,
# in particular regarding the standardized folder structure mentioned there. 
import pandas as pd
import numpy as np

configfile: "config/config.yaml"

def final_output():
    final_output = []
    for g in lookup(dpath="groups", within=config):
        final_output.extend(
            expand(
                "results/samples/{group}/illumina/{group}.{alias}.{coverage}X.mean_fragment_nucleotides_{mean_nuc}.{read}.fq.gz",
                group=g,
                alias=lookup(dpath=f"groups/{g}", within=config),
                coverage=["70"],
                mean_nuc=["300"],
                read=["1", "2"],
            )
        )
        final_output.extend(
            expand(
                "results/samples/{group}/nanopore/{model}/{group}.{alias}.{coverage}X.mean_fragment_nucleotides_{mean_nuc}.simulated_reads.fq",
                group=g,
                model=["human_NA12878_DNA_FAB49712_guppy/training"],
                alias=lookup(dpath=f"groups/{g}", within=config),
                coverage=["25"],
                mean_nuc=["30000"],
            )
        )
    return final_output

rule all:
    input: final_output()

rule get_chromosomes_ref:
    output:
        "resources/chromosome_{chrom}.fa.gz",
    params:
        species=lookup(dpath="reference/species", within=config),
        datatype="dna",
        build=lookup(dpath="reference/build", within=config),
        release=lookup(dpath="reference/release", within=config),
        chromosome=["{chrom}"]
        # branch="plants",  # optional: specify branch
    log:
        "logs/get_chromosome_{chrom}_ref.log",
    cache: "omit-software"  # save space and time with between workflow caching (see docs)
    wrapper:
        "v4.3.0/bio/reference/ensembl-sequence"


rule config_segment_to_bed:
    output:
        bed="results/segments/{circle}.{segment}.bed"
    log:
        "logs/segments/{circle}.{segment}.bed.log"
    params:
        segment=lambda wc: lookup(dpath=f"circles/{wc.circle}/{wc.segment}", within=config)
    run:
        with open(output["bed"], "w") as bed:
            bed.write(f"{params.segment['chrom']}\t{params.segment['start']}\t{params.segment['end']}\t{params.segment['name']}\t\t{params.segment['strand']}")


rule segment_bed_to_fasta:
    input:
        fasta=lambda wc: f"resources/chromosome_{lookup(dpath=f"circles/{wc.circle}/{wc.segment}/chrom", within=config)}.fa.gz",
        bed="results/segments/{circle}.{segment}.bed"
    output:
        fasta="results/segments/{circle}.{segment}.fa.gz"
    log:
        "logs/segments/{circle}.{segment}.fa.log"
    params:
        command="subseq",
    threads: 2
    wrapper:
        "v4.3.0/bio/seqkit"


rule segment_fasta_rename:
    input:
        fasta="results/segments/{circle}.{segment}.fa.gz"
    output:
        fasta="results/segments/{circle}.{segment}.circle_name.fa.gz"
    log:
        "logs/segments/{circle}.{segment}.circle_name.fa.log"
    params:
        command="replace",
        extra='-p "^" -r "{circle} {segment} "'
    threads: 2
    wrapper:
        "v4.3.0/bio/seqkit"


rule create_full_circle:
    input:
        fastas=lambda wc: expand(
            "results/segments/{{circle}}.{segment}.circle_name.fa.gz",
            segment=lookup(dpath=f"circles/{wc.circle}", within=config).keys(),
        ),
    output:
        fasta="results/circles/{circle}.fa.gz"
    log:
        "logs/circles/{circle}.log"
    params:
        command=lambda wc, input: "concat" if len(input.fastas) > 1 else "grep",  # do-nothing grep for circle name if only one segment in circle
        extra=lambda wc, input: "" if len(input.fastas) > 1 else f'-r -p "{wc.circle}"',
    threads: 2
    wrapper:
        "v4.3.0/bio/seqkit"


rule create_full_sample:
    input:
        fastas=lambda wc: expand(
            "results/circles/{circle}.fa.gz",
            circle=lookup(dpath=f"groups/{wc.group}/{wc.alias}", within=config),
        ),
    output:
        fasta="results/samples_references/{group}.{alias}.fa"
    log:
        "logs/samples_references/{group}.{alias}.log"
    conda: "envs/gzip.yaml"
    threads: 1
    shell:
        "zcat {input.fastas} >{output.fasta} 2>{log}"


rule get_circle_stats:
    input:
        fasta="results/samples_references/{group}.{alias}.fa"
    output:
        tsv="results/samples_references/{group}.{alias}.stats.tsv"
    log:
        "logs/samples_references/{group}.{alias}..stats.log"
    params:
        command="stats",
        extra="--tabular"
    threads: 2
    wrapper:
        "v4.3.0/bio/seqkit"


rule sliding_window_around_circle_references:
    input:
        fasta="results/samples_references/{group}.{alias}.fa",
    output:
        fasta="results/samples_references/{group}.{alias}.circular_sliding_windows.fa",
    log:
        "logs/samples_references/{group}.{alias}.circular_sliding_windows.log"
    params:
        command="sliding",
        extra="--circular-genome -W 3996 -s 999",
    threads: 2
    wrapper:
        "v4.3.0/bio/seqkit"


def determine_fragment_number(wildcards, input):
    stats = pd.read_csv(input.tsv, delimiter="\t")
    total_length = int(stats.loc[0, "sum_len"])
    return int( np.ceil( total_length * int(wildcards.coverage) / int(wildcards.mean_nuc) ) )

rule simulate_illumina_reads:
    input:
        fasta="results/samples_references/{group}.{alias}.circular_sliding_windows.fa",
        tsv="results/samples_references/{group}.{alias}.stats.tsv",
    output:
        fq1="results/samples/{group}/illumina/{group}.{alias}.{coverage}X.mean_fragment_nucleotides_{mean_nuc}.1.fq.gz",
        fq2="results/samples/{group}/illumina/{group}.{alias}.{coverage}X.mean_fragment_nucleotides_{mean_nuc}.2.fq.gz",
    log:
        "logs/samples/{group}/illumina/{group}.{alias}.{coverage}X.mean_fragment_nucleotides_{mean_nuc}.log",
    conda: "envs/mason.yaml"
    params:
        fragment_number=lambda wc, input: determine_fragment_number(wc, input),
        read_length=lambda wc: int( int(wc.mean_nuc) / 2),
    threads: 4
    shell:
        "mason_simulator "
        " --input-reference {input.fasta} "
        " --out {output.fq1} "
        " --out-right {output.fq2} "
        " --num-threads {threads} "
        " --fragment-mean-size 350 "
        " --illumina-read-length {params.read_length} "
        " --num-fragments {params.fragment_number} "
        " 2> {log}"


rule download_nanosim_genome_model:
    output:
        model=multiext(
            "resources/human_NA12878_DNA_FAB49712_guppy/training",
            "_aligned_reads.pkl",
            "_aligned_region.pkl",
            "_chimeric_info",
            "_error_markov_model",
            "_error_rate.tsv",
            "_first_match.hist",
            "_gap_length.pkl",
            "_ht_length.pkl",
            "_ht_ratio.pkl",
            "_match_markov_model",
            "_model_profile",
            "_reads_alignment_rate",
            "_strandness_rate",
            "_unaligned_length.pkl",
        ),
    conda: "envs/download.yaml"
    log: "logs/human_NA12878_DNA_FAB49712_guppy/training_download.log",
    shell:
        "cd resources/; "
        "wget https://github.com/bcgsc/NanoSim/raw/v3.1.0/pre-trained_models/human_NA12878_DNA_FAB49712_guppy.tar.gz; "
        "tar xzf human_NA12878_DNA_FAB49712_guppy.tar.gz; "


def determine_nanopore_read_number(wildcards, input):
    stats = pd.read_csv(input.tsv, delimiter="\t")
    total_length = int(stats.loc[0, "sum_len"])
    target_coverage = int(wildcards.coverage)
    mean_read_length = int(wildcards.mean_len)
    return total_length * target_coverage / mean_read_length


rule simulate_nanopore_reads:
    input:
        reference_genome="results/samples_references/{group}.{alias}.fa",
        model=multiext(
            "resources/{model}",
            "_aligned_reads.pkl",
            "_aligned_region.pkl",
            "_chimeric_info",
            "_error_markov_model",
            "_error_rate.tsv",
            "_first_match.hist",
            "_gap_length.pkl",
            "_ht_length.pkl",
            "_ht_ratio.pkl",
            "_match_markov_model",
            "_model_profile",
            "_reads_alignment_rate",
            "_strandness_rate",
            "_unaligned_length.pkl",
        ),
        tsv="results/samples_references/{group}.{alias}.stats.tsv"
    output:
        reads="results/samples/{group}/nanopore/{model}/{group}.{alias}.{coverage}X.mean_fragment_nucleotides_{mean_nuc}.simulated_reads.fq",  # fastq output requires specification of a --basecaller
        errors="results/samples/{group}/nanopore/{model}/{group}.{alias}.{coverage}X.mean_fragment_nucleotides_{mean_nuc}simulated_errors.txt",
        unaligned_reads="results/samples/{group}/nanopore/{model}/{group}.{alias}.{coverage}X.mean_fragment_nucleotides_{mean_nuc}simulated_reads.unaligned.fq",  # asking for unaligned_reads implicitly turns off --perfect
    log:
        "logs/samples/{group}/nanopore/{model}/{group}.{alias}.{coverage}X.mean_fragment_nucleotides_{mean_nuc}.log",
    params:
        extra=lambda wc, input: f"--number {determine_fragment_number(wc, input)} --median_len {wc.mean_nuc} --sd_len {np.log(int(wc.mean_nuc) / 3)} --basecaller guppy -dna_type circular", # --median_len is really used as the mean length argument in numpy.random.lognormal, see here: https://github.com/bcgsc/NanoSim/blob/23911b67ce4733f0468ac26296e25348e3b73b4b/src/simulator.py#L1411
    threads: 4
    wrapper:
        "feat/add-nanosim-wrapper/bio/nanosim/simulator"
